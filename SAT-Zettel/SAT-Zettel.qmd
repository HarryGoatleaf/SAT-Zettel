---
author: "Peter Reithofer"
title: "SAT-Zettel"
format:
  html:
    theme: darkly
    toc: true
    toc-depth: 5
    number-sections: true
    self-contained: true
    monofont: "Fira Code"
---

<!-- Numbers -->
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
<!-- Intervals -->
\newcommand{\I}{\mathbb{I}}
\newcommand{\lA}{\underline{A}}
\newcommand{\uA}{\overline{A}}
\newcommand{\lB}{\underline{B}}
\newcommand{\uB}{\overline{B}}
<!-- Formulas -->
\newcommand{\nxs}{x_1,...,x_n}
\newcommand{\phi}{\varphi}
\newcommand{\FO}{\text{FO}}

## SAT

### Propositional Logic

::: {#def-propositional-logic}
#### Propositional Logic
Let $AP$ be a set of Boolean variables (atomic propositions)
then a grammar for all **propositional logic formulae** (PropForm)
is:

$$\phi := a | (\neg \phi) | (\phi \land \phi) \text{, for } a \in AP$$

Some terminology:

* **Literal**: Either variable or negation of variable.
* **Term**: Conjunction of literals.
* **Clause**: Disjunction of literals.
:::

::: {#def-assignment}
#### Assignment
An **assignment** is an interpretation that assigns a truth value to all
variables in AP. We call the set of all assignments Assign.
We can see an assignment $\alpha$ as a:

* mapping $\alpha: AP \rightarrow \{0, 1\}$
* set of all true variables $\alpha \in \mathfrak{P}(AP)$
* encoding as a bitstring $\alpha \in \{0, 1\}^{AP}$
:::

::: {#def-sat}
#### Satisfaction
We can inductively define the truth value of a formula and write
$\alpha \models \phi$ iff the truth value of $\phi$ is $1$ under 
the assignment $\alpha$.

$sat$ maps each formula to the set of assignments that satisfy it:
$$ sat : PropForm \rightarrow \mathfrak{P}(Assign), 
\phi \mapsto \{\alpha \in Assign | \alpha \models \phi \}$$

We can extend $\models$ to sets of assignments and other formulas.
For $T \subseteq Assign$ we say that
$$T \models \phi \text{ iff. } T \subseteq sat(\phi)$$
and 
$$\phi_1 \models \phi_2 \text{ iff. } sat(\phi_1) \subseteq sat(\phi_2)$$
:::

A formula $\phi$ is:

* **valid** iff $sat(\phi) = Assign$
* **satisfiable** iff $sat(\phi) \neq \emptyset$
* **unsatisfiable** iff $sat(\phi) = \emptyset$


#### Normalforms

::: {#def-nnf}
##### Negation Normal Form (NNF)
\

* contains only $\neg, \land, \lor$
* only variables are negated
* conversion to NNF can be done by pushing negations to atoms with DeMorgan 
  and can be achieved in linear time
:::

::: {#def-dnf}
##### Disjunctive Normal Form (DNF)
\

* disjunction of terms
* Sat problem is linear
* Unsat problem is NP-complete
* conversion to DNF is NP-complete
:::

::: {#def-cnf}
##### Conjunctive Normal Form (CNF) 
\

* conjunction of clauses
* Sat problem is NP-complete
* Unsat problem is linear
* conversion to CNF is NP-complete
:::

#### Tseitin's encoding
'Conversion' to CNF.
Not logically equivalent but sat equivalent.

**Procedure**:

* Add auxiliary variables $h_1,...,h_n$ for each subformula.
* Encode semantic of aux vars in clauses
* Enforce validity of $h_1$ in one clause

### Proof System

::: {#def-proof-system}
#### Proof System
Consists of a set of *axioms* and *inference rules* of the form
$\frac{\text{Antecedents}}{\text{Consequents}}$.

For a proof system $\mathcal{H}$ we define the provability relation $\vdash_\mathcal{H}$.
$\Gamma \vdash_\mathcal{H} \phi$ holds iff. we can proove $\phi$ in $\mathcal{H}$ with premises
from $\Gamma$.

Proof systems can be:

* **Sound**: all derivable sentences are "true" \
  if $\vdash_\mathcal{H} \phi$ then $\models \phi$
* **Complete**: all "true" sentences are derivable \
  if $\models \phi$ then $\vdash_\mathcal{H} \phi$
:::

::: {#def-resolution}
#### Resolution
The resolution inference rule:

$$\frac{(I \lor A) \ (\neg I \lor B)}{(A \lor B)}$$

*Sound and complete* proof system for *CNF*.
If the input formula is unsatisfiable there exists a proof of the empty clause.
:::

### SAT solving
From now on we assume a formula in CNF.

#### Enumeration
Idea
: Go through all (partial)-assignments and check whether they satisfy the formula.

**Algorithm**:

* while variables are unassigned:
  * Assign value to unassigned variable
  * if current partial assignment satisfies formula: return Sat
  * if current partial assignment unsatisfies formula: revert decision (backtrack)

**Properties**:

* if unsat, all assignments need to be ckecked (slow)
* if sat, variable and sign ordering strongly influences runtime.

<!--
```python
#| echo: false
from z3 import *
# whack hack
import os,sys #,inspect
currentdir = os.getcwd()
parentdir = os.path.dirname(currentdir)
pythondir = os.path.join(parentdir, 'python')
sys.path.insert(0,pythondir)
if not os.path.isdir(pythondir):
  raise Exception(os.getcwd())
# now import own classes
import classes.cnf as cnf
```
-->

```python
def enumeration(phi, sign):
  # check if phi is in cnf
  if not cnf.is_cnf(phi):
    raise Exception("Formula is not in CNF.")
  # get free variables in formula
  variables = [key.n for key in cnf.get_vars(phi)]

  # stack of entries 
  # (variable, variable_assignment, b_flag) 
  trail = []

  def decide():
    if len(trail) >= len(variables):
      return False
    cur_var = variables[len(trail)]
    trail.append((cur_var, sign, False))
    return True

  def backtrack():
    while len(trail) > 0:
      (var, val, flag) = trail.pop()
      if not flag:
        # found unexplored subtree
        trail.append((var, not val, True))
        return True
    # explored all assignments
    return False
  
  while(True):
    if not decide():
      if cnf.check_partial_assignment(phi, trail):
        return True
      elif not backtrack():
        return False
```

#### Boolean constraint propagation

For a partial assignment we define the status of a clause:

* **satisfied**: at least one literal is satisfied
* **unsatisfied**: all literals are assigned but clause isn't satisfied
* **unit**: all but one literal are assigned but clause isn't satisfied
* **unresolved**: else

Decision Level (DL)
: Counts the number of decisions (without propagations).

Antecedent (I)
: Unit clause implying the value of literal I (nil if decision).

Algorithm:

* while variables are unassigned:
  * Assign value to unassigned variable
  * while there are unit clauses:
    * set unasigned var in clause to true
  * if current partial assignment satisfies formula: return Sat
  * if current partial assignment unsatisfies formula: revert decision (backtrack)

::: {#def-watched-literals}
##### Watched literals
Book-keeping to quickly find unit clauses.

For each clause we **watch** two different literals such that

* either one is true
* or both are unassigned
  
If we now assign a value to a literal $I$ we refresh the watched literals in
all clauses where we watch $I$. If we can't find new watch candidates we
know the clause is unit.
This way we only need to look at the clauses where we watch $I$ and not all clauses.
:::

#### Boolean Conflict Resolution

::: {#def-implication-graph}
##### Implication Graph
*Directed graph* that represents *propagations* that lead to a (partial) variable assignment.
Usefull to find causes of conflicts.

* Nodes: 
  * assigned variables \
    Which we label with: `x = value(x)@decisionlevel(x)`
  * (if present) conflict node $\kappa$
* Edges:
  * (**from:** *false literals*, **to:** *true literal*) for each ex-unit clause. \
    Which we label with the ex-unit clause.
  * (**from:** *false literals*, **to:** $\kappa$) \
    Which we label with conflicting clause.
:::

::: {#def-conflict-clause}
##### Conflict clauses
Let $L$ be a set of literals that form a cut in an implication graph,
that separates roots (decision) from the conflict node.
By "form a cut" we mean that $L$ includes all nodes whose outgoing edges are cut.

Then $\bigvee_{I \in L} \neg I$ is a **conflict clause**.

* is false under the current (partial)-assignment
* its satisfaction is *necessary* for the satisfaction of the formula
* there can be multiple conflict clauses.
:::

::: {.callout-warning}
Not to be confused with *conflicting clauses*. These are the clauses in the *input formula*
that are false under the current assignment.
:::

::: {#def-asserting-clause}
##### Asserting Clause
Asserting clauses are *conflict clauses* with a single literal from the current decision level.

Some terminology:

* **unique implication point** (UIP): node $v \neq \kappa$ such that all paths from last decision to
  $\kappa$ go through $n$.
* **first UIP**: the UIP closest to $\kappa$
:::

**Finding asserting clause with implication graph:** \
Find the cut that is defined by the *first UIP* and root nodes.
The *conflict clause* corresponding to this cut is asserting.

**Finding assering clauses with resolution:** \

* Start with *conflicting clause*.
* Resolve current clause with antecedent of assigned literals in reverse order.
* Stop when current clause is asserting.

**Algo**: \
After each conflict apply conflict resolution and add the asserting clause to the formula
before backtracking.

::: {.callout-note}
At DL0 only those variables are assigned that appear in a clause with a single literal.
If we have a conflict at DL0 we know that there is a variable that appears positive and
negated in two clauses with only one literal.
Thus we can resolve the empty clause.

<!-- TODO: verify this -->
If a formula is unsat our algo always finds a way to resolve the empty clause.
:::

#### Heuristics

::: {#def-static-heuristic}
#### Static decision heuristic

Static variable order and constant sign.

Always choose lowest variable in order and assign sign value first.
:::

::: {#exm-static-heuristic}
\

$x < y < z$ sign: try positive first.
:::

::: {#def-dlis}
#### DLIS 

The *Dynamic Largest Individual Sum* heuristic
chooses literal that satisfies the most clauses.

When making a decision calculate for each literal $l$:
$$C_l := \text{number of unresolved clauses in which } l \text{ appears}$$
and choose $l$ such that $C_l$ is maximal.
:::

::: {#exm-dlis}
\

$\phi = (x \lor y) \land (x \lor \neg z)$ and no assignments \
$C_{x} = 2 \ \geq \ C_{y} = 1 \ \geq \ C_{\neg z} = 1 (\geq 0 = C_{\neg x} = C_{\neg y} = C_{z})$ \
$\Rightarrow$ assign `true` to $x$.
:::

::: {#def-jeroslow-wang}
#### Jeroslow-Wang method

Prioritises literals that appear in shorter clauses.

For each literal $l$ define:
$$ J(l) := \Sigma_{\text{clause } c \text{ containing }l} 2^{-|c|} $$

Always choose literal that maximizes $J(l)$.
:::

::: {#def-vsids}
#### VSIDS 

The *variable state independent decaying sum* heuristic
prioritises variables that were recently involved in conflicts.

State:

* Counter for every variable
* Increment value

Heuristik:

* when conflict occurs increment every variable that occured in a clause that was used for resolution
* increase increment value
* periodically divide all counters and increment value

<!-- TODO: try first? -->
:::

#### Unsatisfiable core

::: {#def-unsat-core}
##### Unsat core

The unsatisfiable core of an unsatisfiable CNF formula is an unsatisfiable subset
of the original set of clauses.

\
:::

::: {#def-resolution-graph}
##### Resolution Graph

For an **unsat** formula, the resolution graph is:

* Nodes: all original, learned clauses and the empty clause
* Edges: directed edge to every learned clauses from the clauses that resolved to it
:::

We can find an *inclusion minimal* unsat core from a resolution graph by taking
every original clause from which we can reach the empty clause.

## SMT

### First Order Logic

<!--
::: {#def-first-order-theory}
#### First Order Logic
test

test
::: 
-->

::: {#def-theory}
#### Theory
Let $\Sigma$ be a signature. Then a theory $T$ is defined by a set of
$\Sigma$-sentences.

We will often define theories as the smallest set that is closed under
a inference from a sound inference system and includes a set of *axioms*.
:::

:::{.callout-important}
#### Difference to MaLo definition

* Theories don't need to be closed unter inference
* Theories don't need to be satisfiable
:::

Let $\phi$ be a $\Sigma$-formula, then $\phi$ is:

* *T-satisfiable* iff. there exists a structure
  that satisfies $T$ and $\phi$.
* *T-valid* iff. all structures that satisfy T also satisfy $\phi$

::: {#def-fragment}
#### Fragments
Restrict the grammar of FO.

\
:::

:::{#exm-fo-fragments}
#### Example Fragments
\

* quantifier-free fragment
* conjunctive fragment
* 2-CNF (only clauses with two literals)
* equality logic (no functions and predicates)
:::

Eager SMT Solving
: transform FO-formula to sat-equivalent propositional formula and apply with SAT-solving.

Full Lazy SMT Solving
: find solutions for *boolean skeleton* of formulas and use *theory solver* to check
satisfiability of conjunction of predicates. Use *explanation* from theory
solver to modify formula.

Less Lazy SMT Solving
: also check satisfiability of partial assignments.

Requirements for theory solver in Less Lazy SMT Solving:

* (Preferably minimal) **infeasible subsets**: compute reason for unsatisfaction
* **Incrementality**: possible to efficiently extend set of constraints
* **Backtracking**: should be able to remove constraints in reverse chronological order

## Equality Logic with Uninterpreted Functions

::: {#def-wq+uf}
### Equality Logic with Uninterpreted Functions

The signature $\Sigma$ contains:

* variables $x$
* constants $c$
* function symbols $F$
* equality as a predicate

Terms
: $t := c \ | \ c \ | \ x \ | \ F(t,...,t)$

Formulas
: $\phi := (t=t) \ | \ (\phi \land \phi) \ | \ (\neg \phi)$
<!--
\begin{tabular}{ccccccc}
Term: $t$       & $=$ & $c$     & | & $x$               & | & $F(t,...,t)$ \\
Formula: $\phi$ & $=$ & $(t=t)$ & | & $(\phi \land \phi)$ & | & $(\neg \phi)$
\end{tabular}
| Terms:    | $t$    | $=$ | $c$   | $x$               | $F(t,...,t)$  |
|:---------:|:------:|:---:|:-----:|:-----------------:|:-------------:|
| Terms:    | $t$    | $=$ | $c$   | $x$               | $F(t,...,t)$  |
| Formulas: | $\phi$ | $=$ | $(t=t)$ | $(\phi \land \phi)$ | $(\neg \phi)$ |
-->

Problem
: Given a *quantifier free* $\phi \in \FO (\Sigma)$ in NNF,
  can we find a structure $\mathfrak{A}$ and values for the variables $\alpha$ such that
  $$ \mathfrak{A}, \alpha \models \phi$$
:::

<!-- TODO: sehr freie def. vllt bezug zum VL formalismus herstellen -->
<!-- TODO: evtl motivation -->

### Ackermann's reduction
Transforms formula to an equisatisfiable formula without uninterpreted functions.

**Algorithm**:

* For each function $F$ in $\phi$:
  * Introduce new variable for every occurence of $F$
  * Let $\mathcal{T}$ be the function that replaces each occurrence of $F$ with corresponding variable
* $\phi_\text{flat} := \mathcal{T}(\phi)$
* $\phi_\text{cong} := \bigwedge_{1 \leq i < j \leq m}
  (\mathcal{T}(arg(F_i)) =
   \mathcal{T}(arg(F_j))) \rightarrow (f_i = f_j)$
   
**Result**:

* $\phi_{cong} \land \phi_{flat}$ is satisfiability equivalent to $\phi$
* $\phi_{cong} \leftarrow \phi_{flat}$ is UNSAT iff. $\phi$ is valid

### Eager SMT for equalities

::: {#def-equality-graph}
#### Equality Graphs
Let $\phi$ be a quantifier-free FO formula (with equalities) in NNF.
Then it's polar E-Graph is $(V, E_=, E_\neq)$, where

* $V$ is the set of variables
* $E_= := \{ \{x,y\} \vert x=y \text{ is an equality in } \phi\}$
* $E_\neq := \{ \{x,y\} \vert \neg(x=y) \text{ is disequality in } \phi\}$

and it's non-polar E-Graph is $(V, E_= \cup E_\neq)$
:::

<!-- TODO: evtl include some intuition about equivalence class corresponds to connected components
::: {.callout-note collapse="true"}
####### Intuition

If we consider the subgraph induced by all edges that represent a true constraint,
two variables that are in the same connected component are all equal.
:::
-->

::: {#def-contradictory-cycle}
#### Contradictory Cycle
A cycle is

* *contradictory* iff. it contains exactly one edge from $E_\neq$
* *simple* iff. it does not visit nodes twice
:::

:::{.callout-note}
The existence of a contradictory cycle does not imply that the formula is UNSAT!
The E-Graph is an *abstraction* of $\phi$ and ignores it's Boolean structure.
A contradictory cycle only means, that if we make all $=$ true we have to make
the $\neq$ constraint false.
:::


#### Preprocessing
We first simplify the formula.
We know that we can trivially satisfy all constraints that
do not lie on a contradictory cycle because the domain is significantly large.
Thus we replace these constraints with true and simplify the formula.

#### The Sparse Method based on polar E-Graphs

Idea
: Require that for ever circle in the E-Graph, transitivity is ensured.

**Algorithm**:

* Let $\phi_{sk}$ be $\phi$ where every constraint $(x=y)$ is replaced by a fresh 
  Boolean variable $z_{x,y}$ 
  (and thus constraints $(x \neq y) \equiv \neg (x=y)$ by $\neg z_{x,y}$).
* Construct polar E-Graph $G := (V, E_=, E_\neq)$
* Then for every simple contradictory cycle $c = (e_1, ..., e_k)$ where 
  $e_1,...,e_{k-1} \in E_=$ and $e_k \in E_\neq$ we define
  $$
  \phi_{trans}^{c} := \left(\bigvee_{1 \leq i \leq k-1} \neg z_{e_1} \right) \lor z_{e_k}
  $$
  which guarantees, that if all equalities are satisfied on a contradictory cycle
  then the disequality is not satisfied
  ($z_{e_k}$ appears negated in $\phi_{sk}$).
* $\phi^{pol}_{trans} := \bigwedge_{\text{contradictory cycle } c} \phi^c_{trans}$

**Result**:
Satisfiability equivalent formula of $\phi$ is $\phi_{sk} \land \phi^{pol}_{trans}$

:::{.callout-note collapse="true"}
####### What about other simple cycles?

If we have a cycle consisting of edges from $E_=$ and
we find a solution where exactly one constraint on the cycle
is false the solution would also violate our theory.

**Example**: \
$\phi := x_1 = x_2 \lor x_2 = x_3 \lor x_3 = x_1$ \
would result in: $\phi_{sk} = z_{x_1, x_2} \lor z_{x_2, x_3} \lor z_{x_3, x_1}$ \
and because we don't have any contradictory cycles $\phi^{pol}_{trans} = true$. \
Thus a possible solution would be $z_{x_1, x_2} = z_{x_2, x_3} = true; z_{x_3, x_1} = false$
which violates our theory because $=$ is transitive.

However we can simply make this constraint (in our example $x_{x_3, x_1}$) to true and because
we assume that $\phi$ is in NNF we will only make the formula
"more true" 
<!-- (**monotonicity** of NNF) -->
.
:::

:::{.callout-important}
There can potentially be an **exponential** number of simple contradictory cycles!
:::

#### Chordal Method based on non-polar E-Graphs
Idea
: Add edges until the graph is composed only of (polynomially many) triangles.
  Then it suffices to require transitivity of every triangle.

::: {#def-chordal}
##### Chordal
A cycle is *chord-free* iff. we can't replace multiple consecutive edges by one edge.

A graph is chordal iff. every simple cycle over at least 4 different nodes is chordal.
:::

How to make a graph cordal
: For every simple chord-free cycle over more than 4 nodes.
  Take any node and connect it directly to all other nodes on cycle.

**Algorithm**:

* Let $\phi_{sk}$ be $\phi$ where every constraint $(x=y)$ is replaced by a fresh 
  Boolean variable $z_{x,y}$ 
  (and thus constraints $(x \neq y) \equiv \neg (x=y)$ by $\neg z_{x,y}$).
* Construct non-polar E-Graph $G := (V, E_=)$
* Then for every traingle $t = (e_1, e_2, e_3)$
  $$ \phi_{trans}^{c} := (e_1 \land e_2) \rightarrow e_3 \land $$
  $$                  (e_2 \land e_3) \rightarrow e_1 \land $$
  $$                  (e_1 \land e_3) \rightarrow e_2 $$
  which guarantees the transitivity in $t$.
* $\phi^{pol}_{trans} := \bigwedge_{\text{contradictory cycle } c} \phi^c_{trans}$

**Result**:
Satisfiability equivalent formula of $\phi$ is $\phi_{sk} \land \phi_{trans}$

### Lazy Approach

## Bitvector Arithmetic (Bit-Blasting)

**Eager Approach**:

* Build propositional flattening
* Add Boolean variable for each bit of each sub-expression
* Add constraints for each sub-expression

## Linear Arithmatik

## Fourier Motzkin

Extension of Gauss.

Checks satisfiability of a conjunction (theory solver) of *non-strict* inequalities.
Or in other words given $A \in R^{m \times n}$ and $b \in R^m$
is there an $x \in R^n$ such that:

$$ Ax \leq b $$

::: {.callout-note}
Can be extendet to also handle strict inequalities.
:::

::: {.callout-tip}
$=$ constraints can be substituted by two $\leq$ constraints.
:::

**Algorithm**:

* While there is a free variable $x$:
  * Bring $x$ to one hand side of each equation in which it appears
  * Separate these into lower $L$ and upper $U$ bounds:
  $$ \begin{array}{l|rcl} 
  \text{lower bound:} & \text{lbound}  \leq & x & \\
  \text{upper bound:} &                     & x & \leq \text{ubound}
  \end{array} $$
  * If $L = \emptyset$ or $U = \emptyset$ the variable is *unbounded* and we can
    remove it and all constraints containing it!
  * Otherwise we only need to check if $\text{lbound} \leq \text{ubound}$ for all
    $\text{lbound} \in L, \text{ubound} \in U$.
    * If they both don't contain free variables the evaluation is straightforeward.
    * If they contain free variables we **symbolically** evaluate them by adding
      the constraint to our set
      
**Runtime**:

For $m$ constraints in $d$ variables we have a worst-case complexity of:
$4 \cdot (\frac{m}{4})^{2^d}$

## Simplex

Checks satisfiability of a conjunction (theory solver) of *non-strict* inequalities.
Or in other words given $A \in \Q^{m \times n}$ and $b \in \Q^m$
is there an $x \in \R^n$ such that:

$$ Ax \leq b $$

::: {#def-simplex-general-form}
### General Form
We can bring a simplex instance into general form by introducing **slack variables**
$\vec{s} = (s_1,...,s_m)$ for each inequality.
We then transform each inequality to an equality and a bound on its slack variable.
The problem in **general form** is then given by:

$$ 
A' \cdot \left( \begin{array}{c} \vec{x} \\ \vec{s} \end{array}\right) = 0
\text{ and } \bigwedge_{1 \leq i \leq m} l_i \leq s_i \leq u_i
$$
:::

## Branch&Bound

Is a modification Simplex that deals with *integer linear programms* (ILP).
ILP's are generally undecidable. "Branch and Bound" is incomplete.

* Calculate solution for "relaxed system" (i.e. find solution in $\R$)
* if none exists return unsat ("bound")
* if solution is in $\N$ return it
* if solution $\vec{x}$ has non integer component $i$:
  two recursive calls ("branch"):
  * one with additional constraint $x_i \leq \lfloor \vec{x}_i \rfloor$
  * one with additional constraint $\lceil \vec{x}_i \rceil \leq x_i$

## Non-Linear Arithmatik

## Interval Constraint Propagation

:::{#def-interval}
### Interval
\
An **interval** $A = [ \lA; \uA]$
where 

* *lower bound* $\lA \in \R \cup \{-\infty\}$
* *upper bound* $\uA \in \R \cup \{+\infty\}$

denotes the closed set 
$$[\![A]\!] = \{v \in \R \ \vert \ \lA \leq v \leq \uA \}$$

and is *unbounded* iff ($\lA = - \infty$ or $\uA = + \infty$) and *bounded* otherwise.

Its *width/diameter* is $\infty$ iff it is unbounded and $\uA - \lA$ otherwise.

We denote the set of all such intervals with $\I$ and the diameter function with $D$.

We call a cross product of n interval an **n-dimensional box**.

We present $\emptyset$ by $[1; 0]$
:::

:::{#def-interval-arithmetic}
### Interval arithmetic
\
We extend $+, -, \cdot, \div, \cdot^2, \pm \sqrt{\cdot}$ to intervals in the following way

$$ \text{ op } A = \{ \text{ op } a \ \vert \ a \in [\![A]\!]\}$$
$$ A \text{ op } B = \{ a \text{ op } b \ \vert \ a \in [\![A]\!] , b \in [\![B]\!] \}$$
:::

This means that:

* $A \text{ op } B = [1;0]$ iff. $A = \emptyset \lor B = \emptyset$ and otherwise
* $A + B = [\lA + \lB ; \uA + \uB ]$
* $A - B = [\lA - \uB ; \uA - \lB ]$
* $A \cdot B = [\min C ; \max C]$ where 
  $C = \{\lA \cdot \lB, \lA \cdot \uB, \uA \cdot \lB, \uA \cdot \uB \}$
* $A^2 = (A \cdot A) \cap [0;+\infty]$
* $\pm \sqrt{A} = \begin{cases}
      [- \sqrt{\uA}; + \sqrt{\uA}]                                & \text{if } 0 \in A \\
      [- \sqrt{\uA}; - \sqrt{\lA}] \cup [\sqrt{\lA} ; \sqrt{\uA}] & \text{if } 0 < \lA \\
      [1;0]                                                       & \text{otherwise}
    \end{cases}$
* $A \div B = \begin{cases}
    [\min C; \max C] 
    & \text{if } 0 \notin B \\
    [- \infty; + \infty] 
    & \text{if } 0 \in A \land 0 \in B \\
    [1;0] 
    & \text{if } 0 \notin A \land B = [0;0] \\
    [\min (C \cap R^+); + \infty] 
    & \text{if } 0 \notin A \land 0 \in B \land 
      \exists_{a \in A, b \in B}.(\text{sgn}(a) = \text{sgn}(b))\\
    [- \infty; \max (C \cap R^-] 
    & \text{if } 0 \notin A \land 0 \in B \land
      \exists_{a \in A, b \in B}.(\text{sgn}(a) \neq \text{sgn}(b))\\
  \end{cases}$
  where
  $C = \{\frac{\lA}{\lB}, \frac{\lA}{\uB}, \frac{\uA}{\lB}, \frac{\uA}{\uB}\}$

General Idea of ICP
: Take a set of `QFNRA` constraints and an initial set of boxes $B$.
  Iteratively contract boxes from $B$ without removing solutions from $B$.
  Split boxes with heuristic.
  Once a box' diameter is "sufficiently small" check with a complete procedure if it contains a solution.

### Contraction Method 1

For this method we require that we can bring every variable to one hand side in every constraint.
This is possible for linear-polynomials and monomials.
We make a preprocessing step to eliminate non-linear polynomials.

**Preprocessing**:

* Bring every constraint to the form $p \sim 0$
* We replace every non-linear monomial $m_i$ in all polynomials by a fresh variable $h_i$
* We add $h_i - m_i = 0$ to $C$
* We initialize the bounds for $h_i$ by evaluating $m_i$ and substituting initial box

**Contraction**:

* Choose a constraint $c$ and variable $x$. We will call $(c, x)$ the **contraction candidate** (CC) 
* Bring $x$ to one hand side
* Substitute current bounds to obtain *union of intervals* $B_1,...,B_k$
<!-- this makes no sense -->
* For each $1 \leq i \leq k$:
  * restrict current bounds of $x$ to values that do not conflict with $B_i$

### Contraction Method 2 (Interval Newton Method)

::: {.callout-note}
In this lecture only univariate case.
:::

**Preprocessing**:

* Bring every constraint to the form $p \sim 0$
* Introduce fresh *slack variable* $h$ for each inequation $p \sim 0$ and bring to the form
  $h - p = 0$ and $h \sim 0$ where the bounds from $h$ are obtained by substituting the initial bounds
  in $p$ and from $h \sim 0$.

**Contraction**:

* Take constraint $f(x) = 0$ with starting bounds $A$ and sample point $s \in A$.
* Set new interval to $$A := A \cap \left(s - \frac{f(s)}{f'(s)} \right)$$

## Decomposition
Idea
: Concept to decompose infinite variable domain into finitely many,
  truth-invariant intervals.

Algebra definitions:

* **Degree**:
  * Degree of monomial is sum of exponents.
  * Degree of polynomial is max degree of monomials in canonical form.
* **(real/complex) Root**: $\vec{x} \in \mathbb{R} \text{ resp. } \mathbb{C}$ such that $p(\vec{x}) = 0$
* **Finite abstraction**: finite set of points that contains one point from each sign invariant
    region from $p$

### Algebra facts
* Every *univariate* poly $p$ of degree $d$ has exactly $d$ complex roots and thus at most
  $d$ real roots.
* Sign of $p$ is invariant between two successive roots.
* We can partition $\mathbb{R}$ into at most $2d + 1$ *sign invariant* regions for $p$.

### Invariant regions of single poly
### Invariant regions of multiple polys
### Application
Given a *finite abstraction* of a poly we can easily check if it can satisfy a constraint
by pluging in all *sample points* from the abstraction and evaluating the formula.


## Subtropical Satisfiability Method
### At a glance
* incomplete
* in practice very fast
* theory solver, i.e. does not solve boolean sceleton, only conjunction of constraints.
  In this lecture: only one constraint!
* used for SAT checking on quantifier free fragment of $FO$ on $(R, +, \cdot)$ 
  also called *quantifier free non-linear real arithmatic* (QFNRA).

### Algebra concepts
* **Monomial**: product of variables
* **Term**: product of a coefficient and a monomial
* **Polynomial** (in normal form): sum of *pairwise different* terms
* **Frame**: $p: D[\nxs] \rightarrow \N^n$ 
  maps a poly to set of exponent vectors. Example:
  * $f := x^1y^1 + x + 1$ 
  * $p(f) = \{ (1,1), (1, 0), (0, 0) \}$
* **Newton Polytope**: inclusion minimal convex hull of frame of poly
* **Hyperplane**: can be defined by linear equation

### Notation
* **polynomial ring**: $D[\nxs]$ is the ring of all polynomials with variables
  $\nxs$ over domain $D$.
* **vector**: we will use $\vec{x}$ for $\nxs$

### Algo
**Problem**: given $p \in D[\nxs]$ find $\nxs$ such that $p(\nxs) = 0$.

**Outline**:

1. find $\vec{a}$ such that $p(\vec{a}) < 0$.
2. find $\vec{b}$ such that $p(\vec{b}) > 0$.
3. use $\vec{a}$ and $\vec{b}$ to find $\vec{x}$ such that $p(\vec{x}) = 0$.

#### Part 1 (trivial)
We set $\vec{a} = (1,...,1)$. 

**Case**:

* If by chance $p(\vec{a}) = 0$ we can immediately return.
* If $p(\vec{a}) < 0$ then $\vec{a}$ satisfies our conditions.
* If $p(\vec{a}) > 0$ we solve the equivalent problem $-1 \cdot p = 0$

#### Part 2
For this part we hope that the polynome diverges in any direction to $+\infty$.
If it does we walk into this direction until we find $\vec{b}$.

**Case: Univariate**\
Just check leading coefficient to find out if poly diverges towards $\pm \infty$.

**Case: Multivariate**\
Search for term with positive coeff that can get dominating.
Search for direction in which this term gets dominating.

**Algorithm**:
Find Hyperplane that separates node of Newton Polytope with positive
leading coefficient from the rest of the polytope.
Normalvector of Hyperplane is direction in which the poly diverges.
Use linear programming to find such hyperplane.

#### Part 3
**Problem**: given $\vec{a}$ and $\vec{b}$ such that
$p(\vec{a}) < 0$ and $p(\vec{b}) > 0$ find
$\vec{x}$ such that $p(\vec{x}) = 0$.

**Idea**: because $p$ is continuous we know that $p$ has a root between
$\vec{a}$ and $\vec{b}$.

* We parameterize the segment between $\vec{a}, \vec{b}$:
  $$ s(t) := \vec{a} + t \cdot (\vec{b} - \vec{a}) $$
  And know by "Zwischenwertsatz" that $p(s(t)) = 0$ for some $t \in (0, 1)$.

* Because $p \circ s$ is univariate we can find such a $t$ with common techniques (e.g. bisection)
* Root of $p$ is then given by $s(t)$.


## Cylindrical Algebraic decomposition
### At a glance
* complete (only complete procedure for QFNRA one in this lecture)
* only handles set of constraints
* generates finite set of samples that include all sign invariant regions
* double exponential runtime


### Terminology

Region
: non-empty connected subset of $\R^n$.

Decomposition
: is finite partition where each cell (part of partition) is a region.

::: {#def-cad}
#### Cylindrical Algebraic Decomposition
A CAD is a decomposition that is:

* (semi)-**algebraic**: if each cell can be constructed from poly varieties
  using:
    * finite union
    * intersection
    * complementation
* **cylindrical**: either $n=1$ or any projection to lower dimension is
  cylindrical

CAD of poly is CAD whose cells are sign invariant.
:::

::: {#def-real-algebraic-numbers}
#### Real Algebraic Numbers
A number $a \in \R$ is called real algebraic iff.
there exists poly $p \in \Q[x]$ such that $p(a) = 0$.

We represent $a$ by $(p, I)$ where $I \subseteq \R$ is *open* or a *point*
and $p$ has only on real root in $I$.
:::

::: {#def-cauchy-bound}
#### Cauchy Bound
For $p \in \Q[x]$ with coefficients $a_1,...,a_k$ and leading coeff $l$,
the *cauchy bound* 

$$C := 1 + \max{\frac{|a_i|}{l}}$$
:::

::: {#lem-cauchy-bound}
#### Cauchy Bound application
We know that all real roots of $p$ are in $[-C, C]$.

\
:::

### Sturm sequence

::: {#def-sturm-sequence}
#### Sturm sequence
Let $p \in \Q[x]$ where the factorisation of $p$ has no repreating factors.
Then the **sturm sequence** of $p$ is given by:

* $p_0 = p$
* $p_1 = p'$
* $p_i = -\text{rem}(p_{i-2}, p_{i-1})$
* ...
* $p_k = 0$
:::

::: {#lem-sturm-sequence-application}
#### Sturm sequence application
Let $p \in \Q[x]$ and $(p_0,...,p_k)$ it's sturm sequence.
Further let $\sigma(x)$ be the number of sign changes in 
$(p_0(x), p_1(x),..., p_k(x))$.

Then we know that the number of real roots of $p$ in $(a, b]$ is $\sigma(a) - \sigma(b)$.
:::

[Sturm Sequence Calculator](https://planetcalc.com/7719/)

:::{.callout-important}
In exam sturm sequence will be given!
:::

### Case of $\R$

**Algorithm**:

* Calculate Cauchy Bound $C$
* Start with $r = \{ (-C, C) \}$
* While some interval in $r$ contains more than $1$ real root (calc with Sturm Sequence)
  * split interval

<!-- TODO: what if polys share root??? -->

::: {.callout-note}
Evaluation of polys at algebraic numbers with our representation not handled in
this lecture.
:::

### Case of $\R^n$

Harder because we have potentially infinite varieties.

::: {#def-delineable}
#### Delineability
A poly $p$ is *delineable* on a region $R \subseteq \R^{n-1}$ 
iff.
for each $\vec{a} \in R$ the number of:

* roots of $p(\vec{a},x)$
* different roots of $p(\vec{a},x)$
* common roots of $p(\vec{a},x)$

is constant.
:::

#### Algo
* projection is black-box
* projection gives set of polys with one variable less such that common zeros
  are cylinder boundaries of higher-dim polys.
* projection is hard. is step which makes algo double exp
* three parts:
  * resultant whose roots cover projections of common roots of two polys
  * discriminant whose roots cover projections of points where number of roots
    of single poly changes
  * coefficients whose roots cover divergence points
  * (cover because they may have additional superflous roots)
  
### Generate infeasible subsets

* Collect the violated constraints for each sample point.
* Calculate covering